{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict, namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the ONNX model or onnxruntime\n",
    "\n",
    "# Don't forget to alter the image dimensions accordingly\n",
    "\n",
    "# !py \"../export.py\" --weights \"./yolov7-tiny.pt\" --grid --end2end --simplify --topk-all 100 --iou-thres 0.65 --conf-thres 0.35 --img-size 640 640 --dynamic-batch --max-wh 7680"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = True # For utilizing GPU, and performing parallel computing\n",
    "weights = \"./yolov7-tiny.onnx\"\n",
    "\n",
    "imgList = [\n",
    "    cv2.imread(\"../images/img1.jpg\"),\n",
    "    # cv2.imread(\"../images/img2.jpg\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "providers = [\"CUDAExecutionProvider\", \"CPUExecutionProvider\"] if cuda else [\"CPUExecutionProvider\"]\n",
    "\n",
    "# Creating an inference session to utilize the pre build model\n",
    "session = ort.InferenceSession(weights, providers=providers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated random colors for object bounding boxes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'person': (212, 181, 212), 'car': (6, 188, 245)}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_classes = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', \n",
    "         'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', \n",
    "         'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', \n",
    "         'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', \n",
    "         'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', \n",
    "         'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', \n",
    "         'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', \n",
    "         'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', \n",
    "         'hair drier', 'toothbrush']\n",
    "\n",
    "# Target classes on which I need to focus\n",
    "classes = [\"person\", \"car\"]\n",
    "# Generating random colors or bounding box of each of these classes\n",
    "\n",
    "colors = {}\n",
    "\n",
    "for class_name in classes:\n",
    "\n",
    "    colors[class_name] = tuple([random.randint(0, 255) for _ in range(3)]) # Generating (r, g, b) list\n",
    "\n",
    "print(\"Generated random colors for object bounding boxes\")\n",
    "colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def letterbox(im, new_shape=(640, 640), color=(114, 114, 114), auto=True, scaleup=True, stride=32):\n",
    "\n",
    "    \"\"\"Resize and pad image while meeting stride-multiple constraints\"\"\"\n",
    "    \n",
    "    shape = im.shape[:2]  # current shape [height, width]\n",
    "    if isinstance(new_shape, int):\n",
    "        new_shape = (new_shape, new_shape)\n",
    "\n",
    "    # Scale ratio (new / old)\n",
    "    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n",
    "    if not scaleup:  # only scale down, do not scale up (for better val mAP)\n",
    "        r = min(r, 1.0)\n",
    "\n",
    "    # Compute padding\n",
    "    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))\n",
    "    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding\n",
    "\n",
    "    if auto:  # minimum rectangle\n",
    "        dw, dh = np.mod(dw, stride), np.mod(dh, stride)  # wh padding\n",
    "\n",
    "    dw /= 2  # divide padding into 2 sides\n",
    "    dh /= 2\n",
    "\n",
    "    if shape[::-1] != new_unpad:  # resize\n",
    "        im = cv2.resize(im, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
    "    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\n",
    "    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\n",
    "    im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # add border\n",
    "    return im, r, (dw, dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing the images\n",
    "\n",
    "rgb_images = []\n",
    "resize_data = []\n",
    "\n",
    "for image in imgList:\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # YOLO requires BGR images to be in RGB form\n",
    "    rgb_images.append(image)\n",
    "\n",
    "    image_cpy = image.copy()\n",
    "    image_cpy, ratio, dwdh = letterbox(image_cpy, auto=False)\n",
    "\n",
    "    image_cpy = image_cpy.transpose((2, 0, 1)) \n",
    "    image_cpy = np.expand_dims(image_cpy, 0) # Adds an extra dimension to image at index 0, YOLOv7 format\n",
    "    image_cpy = np.ascontiguousarray(image_cpy) # Changes the matrix structure of image_cpy, again YOLOv7 format\n",
    "    image_cpy = image_cpy.astype(np.float32)\n",
    "\n",
    "    resize_data.append((image_cpy, ratio, dwdh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['output'], ['images'])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting the names of input, output nodes from ONNX model\n",
    "\n",
    "outname = [i.name for i in session.get_outputs()]\n",
    "inname = [i.name for i in session.get_inputs()]\n",
    "\n",
    "(outname, inname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running batch 1 inference\n",
    "\n",
    "image = np.ascontiguousarray(resize_data[0][0]/255) # Normalizing the image\n",
    "prediction = session.run(outname, {\"images\": image})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thickness = 2\n",
    "\n",
    "for i, prediction_array in enumerate(prediction):\n",
    "    \n",
    "    for (batch_id, x0, y0, x1, y1, cls_id, score) in prediction_array:\n",
    "\n",
    "        class_name = all_classes[int(cls_id)]\n",
    "\n",
    "        if class_name in classes and score > 0.4:\n",
    "            class_color = colors[class_name]\n",
    "\n",
    "            # Reversing the paddings and other transformations applied during letterbox\n",
    "\n",
    "            box = np.array([x0,y0,x1,y1])\n",
    "            box -= np.array(dwdh*2)\n",
    "            box /= ratio\n",
    "            box = box.round().astype(np.int32).tolist()\n",
    "\n",
    "            cv2.rectangle(imgList[0], box[:2], box[2:], class_color, thickness)\n",
    "\n",
    "cv2.imshow(\"Image\", imgList[0])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated random colors for object bounding boxes\n",
      "Avg frame processing time:  0.1386938817360822\n"
     ]
    }
   ],
   "source": [
    "# OpenCV Live feed version\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "\n",
    "cuda = True # For utilizing GPU, and performing parallel computing\n",
    "weights = \"./yolov7-tiny.onnx\"\n",
    "providers = [\"CUDAExecutionProvider\", \"CPUExecutionProvider\"] if cuda else [\"CPUExecutionProvider\"]\n",
    "# Creating an inference session to utilize the pre build model\n",
    "session = ort.InferenceSession(weights, providers=providers)\n",
    "\n",
    "all_classes = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', \n",
    "         'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', \n",
    "         'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', \n",
    "         'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', \n",
    "         'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', \n",
    "         'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', \n",
    "         'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', \n",
    "         'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', \n",
    "         'hair drier', 'toothbrush']\n",
    "\n",
    "# Target classes on which I need to focus\n",
    "# classes = [\"person\", \"car\"]\n",
    "classes = all_classes\n",
    "# Generating random colors or bounding box of each of these classes\n",
    "\n",
    "colors = {}\n",
    "\n",
    "for class_name in classes:\n",
    "\n",
    "    colors[class_name] = tuple([random.randint(0, 255) for _ in range(3)]) # Generating (r, g, b) list\n",
    "\n",
    "print(\"Generated random colors for object bounding boxes\")\n",
    "\n",
    "def letterbox(im, new_shape=(640, 640), color=(114, 114, 114), auto=True, scaleup=True, stride=32):\n",
    "\n",
    "    \"\"\"Resize and pad image while meeting stride-multiple constraints\"\"\"\n",
    "    \n",
    "    shape = im.shape[:2]  # current shape [height, width]\n",
    "    if isinstance(new_shape, int):\n",
    "        new_shape = (new_shape, new_shape)\n",
    "\n",
    "    # Scale ratio (new / old)\n",
    "    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n",
    "    if not scaleup:  # only scale down, do not scale up (for better val mAP)\n",
    "        r = min(r, 1.0)\n",
    "\n",
    "    # Compute padding\n",
    "    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))\n",
    "    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding\n",
    "\n",
    "    if auto:  # minimum rectangle\n",
    "        dw, dh = np.mod(dw, stride), np.mod(dh, stride)  # wh padding\n",
    "\n",
    "    dw /= 2  # divide padding into 2 sides\n",
    "    dh /= 2\n",
    "\n",
    "    if shape[::-1] != new_unpad:  # resize\n",
    "        im = cv2.resize(im, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
    "    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\n",
    "    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\n",
    "    im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # add border\n",
    "    return im, r, (dw, dh)\n",
    "\n",
    "# Starting OpenCV Video Capture\n",
    "\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "if not capture.isOpened():\n",
    "    print(\"Camera being used by another application, unable to gain access\")\n",
    "    exit()\n",
    "\n",
    "outname = [i.name for i in session.get_outputs()]\n",
    "inname = [i.name for i in session.get_inputs()]\n",
    "thickness = 2\n",
    "screen_width = int(capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "screen_height = int(capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "# Create a named window for full screen display\n",
    "cv2.namedWindow(\"Live Footage\", cv2.WINDOW_NORMAL)\n",
    "cv2.setWindowProperty(\"Live Footage\", cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "\n",
    "# Calculating time taken to process each frame\n",
    "start_time = time.time()\n",
    "img_counter = 1\n",
    "\n",
    "# For OpenCV fonts\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_scale = 1.0\n",
    "\n",
    "while True:\n",
    "\n",
    "    ret, frame = capture.read()\n",
    "    # frame_cpy = frame.copy()\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) # YOLO requires BGR images to be in RGB form\n",
    "\n",
    "    resize_data = []\n",
    "\n",
    "    image_cpy, ratio, dwdh = letterbox(image, auto=False)\n",
    "\n",
    "    image_cpy = image_cpy.transpose((2, 0, 1)) \n",
    "    image_cpy = np.expand_dims(image_cpy, 0) # Adds an extra dimension to image at index 0, YOLOv7 format\n",
    "    image_cpy = np.ascontiguousarray(image_cpy) # Changes the matrix structure of image_cpy, again YOLOv7 format\n",
    "    image_cpy = image_cpy.astype(np.float32)\n",
    "\n",
    "    resize_data.append((image_cpy, ratio, dwdh))\n",
    "\n",
    "    # Running batch 1 inference\n",
    "\n",
    "    image = np.ascontiguousarray(resize_data[0][0]/255) # Normalizing the image\n",
    "    prediction = session.run(outname, {\"images\": image})\n",
    "\n",
    "    enu_predic = enumerate(prediction)\n",
    "\n",
    "    for i, prediction_array in enu_predic:\n",
    "    \n",
    "        for (batch_id, x0, y0, x1, y1, cls_id, score) in prediction_array:\n",
    "            # Coordinates are of top left and bottom right\n",
    "\n",
    "            if score < 0.4:\n",
    "                continue\n",
    "\n",
    "            class_name = all_classes[int(cls_id)]\n",
    "\n",
    "            if class_name in classes:\n",
    "                class_color = colors[class_name]\n",
    "\n",
    "                # Reversing the paddings and other transformations applied during letterbox\n",
    "\n",
    "                box = np.array([x0,y0,x1,y1])\n",
    "                box -= np.array(dwdh*2)\n",
    "                box /= ratio\n",
    "                box = box.round().astype(np.int32).tolist()\n",
    "\n",
    "                cv2.rectangle(frame, box[:2], box[2:], class_color, thickness)\n",
    "                cv2.putText(frame, class_name, box[:2], font, font_scale, class_color, thickness)\n",
    "\n",
    "    cv2.imshow(\"Live Footage\", frame)\n",
    "\n",
    "    img_counter += 1\n",
    "    if (cv2.waitKey(1) == ord(\"q\")):\n",
    "        end_time = time.time()\n",
    "        print(\"Avg frame processing time (time taken/ frames processed): \",(end_time- start_time)/img_counter)\n",
    "        break\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.16311155995236168 sec, all\n",
    "# 0.163175533979367 sec, just 2 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
